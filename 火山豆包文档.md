图片理解
最近更新时间：2025.12.01 16:53:40
首次发布时间：2024.11.07 21:54:45
复制全文
我的收藏
有用
无用
部分大模型具备视觉理解能力，如当传入图片时，大模型可理解图片的信息，并结合这些信息完成如描述其中的物体等视觉相关任务。通过这篇教程，你可学习如何通过调用大模型 API 来识别传入图片里的信息。

支持模型
请参见视觉理解。

前提条件
获取 API Key
开通模型服务
在 模型列表 获取所需 Model ID
通过 Endpoint ID 调用模型服务，请参考 获取 Endpoint ID（创建自定义推理接入点）。

API 接口
Responses API：支持图片作为输入进行分析。支持文件路径上传进行图片理解，使用方式参见文件路径上传（推荐）。
Chat API：支持图片作为输入进行分析。

图片传入方式
支持的图片传入方式如下：

本地文件上传：
文件路径上传（推荐）：直接传入本地文件路径，文件大小不能超过 512 MB。
Base64 编码传入：适用于图片文件体积较小的场景，单张图片小于 10 MB，请求体不能超过 64MB。
图片 URL 传入：适用于图片文件已存在公网可访问 URL 的场景，单张图片小于 10 MB。
说明

Chat API 是无状态的，如需模型对同一张图片进行多轮理解，则每次请求时都需传入该图片信息。


本地文件上传

文件路径上传（推荐）
建议优先采用文件路径方式上传本地文件，该方式可以支持最大 512MB 文件的处理。（当前Responses API支持该方式）
直接向模型传入本地文件路径，会自动调用 Files API 完成文件上传，再调用 Responses API 进行图片分析。仅 Python SDK 和 Go SDK 支持该方式。具体示例如下：

如果需要实时获取分析内容，或者要规避复杂任务引发的客户端超时失败问题，可采用流式输出的方式，具体示例见流式输出。
支持直接使用 Files API 上传本地文件，具体请参见Files API 教程。
Python
Go
import asyncio
import os
from volcenginesdkarkruntime import AsyncArk
client = AsyncArk(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=os.getenv('ARK_API_KEY')
)
async def main():
    local_path = "/Users/doc/ark_demo_img_1.png"
    response = await client.responses.create(
        model="doubao-seed-1-6-251015",
        input=[
            {"role": "user", "content": [
                {
                    "type": "input_image",
                    "image_url": f"file://{local_path}"  
                },
                {
                    "type": "input_text",
                    "text": "支持输入图片的模型系列是哪个？"
                }
            ]},
        ]
    )
    print(response)
if __name__ == "__main__":
    asyncio.run(main())

Base64 编码传入
将本地文件转换为 Base64 编码字符串，然后提交给大模型。该方式适用于图片文件体积较小的情况，单张图片小于 10 MB，请求体不能超过 64MB。（Responses API 和 Chat API 都支持该方式。）

注意

将图片文件转换为Base64编码字符串，然后遵循data:{mime_type};base64,{base64_data}格式拼接，传入模型。

{mime_type}：文件的媒体类型，需要与文件格式mime_type对应。支持的图片格式详细见图片格式说明。
{base64_data}：文件经过Base64编码后的字符串。
使用 Responses API 的示例代码如下：
Curl
Python
Go
Java
OpenAI SDK
BASE64_IMAGE=$(base64 < demo.png) && curl https://ark.cn-beijing.volces.com/api/v3/responses \
   -H "Content-Type: application/json"  \
   -H "Authorization: Bearer $ARK_API_KEY"  \
   -d @- <<EOF
   {
    "model": "doubao-seed-1-6-251015",
    "input": [
      {
        "role": "user",
        "content": [
          {
            "type": "input_image",
            "image_url": "data:image/png;base64,$BASE64_IMAGE"
          },
          {
            "type": "input_text",
            "text": "支持输入图片的模型系列是哪个？"
          }
        ]
      }
    ]
  }
EOF
使用 Chat API 的示例代码如下：
Curl
Python
Go
Java
BASE64_IMAGE=$(base64 < demo.png) && curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json"  \
   -H "Authorization: Bearer $ARK_API_KEY"  \
   -d @- <<EOF
   {
    "model": "doubao-seed-1-6-251015",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
              "url": "data:image/png;base64,$BASE64_IMAGE"
            }
          },
          {
            "type": "text",
            "text": "支持输入图片的模型系列是哪个？"
          }
        ]
      }
    ],
    "max_tokens": 300
  }
EOF
按需替换 Model ID，查询 Model ID 参见 模型列表。

图片 URL 传入
如果图片已存在公网可访问URL，可以在请求中直接填入图片的公网URL，单张图片不能超过 10 MB。（Responses API 和 Chat API 都支持该方式。）

说明

如果使用 URL，建议使用火山引擎TOS（对象存储）存储图片并生成访问链接，不仅能保证图片的稳定存储，还能利用方舟与TOS的内网通信优势，有效降低模型回复的时延和公网流量费用。

使用 Responses API 的示例代码如下：
Curl
Python
Go
Java
OpenAI SDK
curl https://ark.cn-beijing.volces.com/api/v3/responses \
-H "Authorization: Bearer $ARK_API_KEY" \
-H 'Content-Type: application/json' \
-d '{
    "model": "doubao-seed-1-6-251015",
    "input": [
        {
            "role": "user",
            "content": [
                {
                    "type": "input_image",
                    "image_url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"
                },
                {
                    "type": "input_text",
                    "text": "支持输入图片的模型系列是哪个？"
                }
            ]
        }
    ]
}'
使用 Chat API 的示例代码如下：
Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}},
                {"type": "text", "text": "支持输入图片的模型系列是哪个？"}
            ]
        }
    ],
    "max_tokens": 300
  }'

使用场景

多图输入
API 可支持接受和处理多个图像输入，这些图像可通过图片可访问 URL 或图片转为 Base64 编码后输入，模型将结合所有传入的图像中的信息来回答问题。

Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json"  \
   -H "Authorization: Bearer $ARK_API_KEY"  \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}},
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_2.png"}},
                {"type": "text", "text": "支持输入图片的模型系列是哪个？同时，豆包应用场景有哪些？"}
            ]
        }
    ],
    "max_tokens": 300
  }'
按需替换 Model ID，查询 Model ID 参见 模型列表。

控制图片理解的精细度
控制图片理解的精细度（指对画面的精细）： image_pixel_limit 、detail 字段，2个字段若同时配置，则生效逻辑如下：

生效前提：图片像素范围在 [196, 36,000,000] px，否则直接报错。
生效优先级：image_pixel_limit 高于 detail 字段，即同时配置 detail 与 image_pixel_limit 字段时，生效 image_pixel_limit 字段配置。
缺省时生效：image_pixel_limit 字段的 min_pixels / max_pixels 字段未设置，则使用 detail （默认值为low）配置所对应的值。
detail为low：min_pixels 值3136 ；max_pixels 值1048576。
detail为high：min_pixels 值3136 ；max_pixels 值4014080。
下面分别介绍如何通过 detail 、 image_pixel_limit 控制视觉理解的精度。

通过 detail 字段（图片理解）
你可通过detail参数来控制模型理解图片的精细度，返回速度，token用量，计费公式请参见token 用量说明。

low：“低分辨率”模式，默认此模式，处理速度会提高，适合图片本身细节较少或者只需模型理解图片大致信息或者对速度有要求的场景。此时 min_pixels 取值3136、max_pixels 取值1048576。不在此范围且小于3600w px的图片，方舟会等比例缩放至范围内。
high：“高分辨率”模式，模型可感知图片更多的细节，但是处理图片速度会降低，适合图像像素值高且需关注细节信息的场景，如街道地图分析等。此时 min_pixels 取值3136、max_pixels 取值4014080。不在此范围且小于3600w px的图片，方舟会等比例缩放至范围内。
Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"},"detail": "high"},
                {"type": "text", "text": "支持输入图片的模型系列是哪个？"}
            ]
        }
    ],
    "max_tokens": 300
  }'
按需替换 Model ID，查询 Model ID 参见 模型列表。

通过 image_pixel_limit 结构体
控制传入给方舟的图像像素大小范围，如果不在此范围，则会等比例放大或者缩小至该范围内，后传给模型进行理解。你可通过 image_pixel_limit 结构体，精细控制模型可理解的图片像素多少。
对应结构体如下：

"image_pixel_limit": {
    "max_pixels": 3014080,   # 图片最大像素
    "min_pixels": 3136       # 图片最小像素
}
示例代码如下：

Java SDK、 Go SDK 不支持此字段。

Curl
Python
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"},"image_pixel_limit": {"max_pixels": 3014080,"min_pixels": 3136}},
                {"type": "text", "text": "支持输入图片的模型系列是哪个？"}
            ]
        }
    ],
    "max_tokens": 300
  }'
按需替换 Model ID，查询 Model ID 参见 模型列表。

图文混排
支持灵活地传入提示词和图片信息的方式，你可任意调整传图图片和文本的顺序，以及在system message或者User message传入图文信息。模型会根据顺序返回处理信息的结果，示例如下。

Curl
Python
Go
Java
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer $ARK_API_KEY" \
   -d '{
    "model": "doubao-seed-1-6-251015",
    "messages": [
        {
            "role": "system",
            "content": [
                {"type": "text", "text": "下面人物是目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/target.png"
                    }
                },
                {"type": "text", "text": "请确认下面图片中是否含有目标人物"}
            ]
        },
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "图片1中是否含有目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/scene_01.png"
                    }
                },
                {"type": "text", "text": "图片2中是否含有目标人物"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://ark-project.tos-cn-beijing.volces.com/doc_image/scene_02.png"
                    }
                }
            ]
        }
    ],
    "max_tokens": 300
  }'
按需替换 Model ID，查询 Model ID 参见 模型列表。
说明

图文混排场景，图文顺序可能影响模型输出效果，若结果不符预期，可调整顺序。当多图+一段文字时，建议将文字放在图片之后。


流式输出
流式输出支持内容动态实时呈现，既能够缓解用户等待焦虑，又可以规避复杂任务因长时间推理引发的客户端超时失败问题，保障请求流程顺畅。

Python
Go
import asyncio
import os
from volcenginesdkarkruntime import AsyncArk

client = AsyncArk(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=os.getenv('ARK_API_KEY')
)

async def main():
    local_path = "/Users/doc/ark_demo_img_1.png"
    stream = await client.responses.create(
        model="doubao-seed-1-6-251015",
        input=[
            {"role": "user", "content": [
                {
                    "type": "input_image",
                    "image_url": f"file://{local_path}"  
                },
                {
                    "type": "input_text",
                    "text": "支持输入图片的模型系列是哪个？"
                }
            ]},
        ],
        caching={
            "type": "enabled",
        },
        store=True,
        stream=True
    )
    async for event in stream:
        if isinstance(event, ResponseReasoningSummaryTextDeltaEvent):
            print(event.delta, end="")
        if isinstance(event, ResponseOutputItemAddedEvent):
            print("\noutPutItem " + event.type + " start:")
        if isinstance(event, ResponseTextDeltaEvent):
            print(event.delta,end="")
        if isinstance(event, ResponseTextDoneEvent):
            print("\noutPutTextDone.")
        if isinstance(event, ResponseCompletedEvent):
            print("Response Completed. Usage = " + event.response.usage.model_dump_json())

if __name__ == "__main__":
    asyncio.run(main())

视觉定位（Visual Grounding）
请参见教程 视觉定位 Grounding。

GUI任务处理
请参见教程 GUI 任务处理。

使用说明
说明

处理完图片/视频后，文件会从方舟服务器删除。方舟不会保留你提交的图片、视频以及文本信息等用户数据来训练模型。


图片像素说明
方舟在处理图片前会先行进行图片尺寸判断，如果图片超出下面的限制，会直接报错，传入图片满足下面条件（单位 px）：
宽 > 14 且 高>14。
宽*高范围： [196, 36,000,000]。
满足上述条件的图片，方舟检测图片大小并将图片等比例压缩，并根据不同模式，将图片像素处理（等比例）至下面范围。
detail:low模式下，104万（1024×1024） px。
detail:high模式下，401万（2048×1960） px。
其中，detail 字段控制理解图像精度，具体请参见理解图像的深度控制。
说明

对图片预处理，如裁剪/压缩图片，控制图片像素（宽×高）在104万（low）/ 401万（high）内，可降低模型响应时延与 token 消耗。


图片数量说明
单次请求传入图片数量受限于模型上下文窗口。当输入过长，触发模型上下文窗口，信息会被截断。

模型上下文窗口请参见模型列表。
举例说明：

当图片总像素值大，使用的模型上下文窗口为 32k token，每张图片转为 1312 token ，单次请求可传入的图片数量为 32000 ÷ 1312 = 24 张。
当图片总像素值小，使用的模型上下文窗口为 32k token，每张图片转为 256 token，单次请求可传入的数量为 32000 ÷ 256 = 125 张。
说明

模型回复的质量，受输入图片信息量影响。过多的图片会导致模型回复质量下滑，请合理控制单次请求传入图片的数量。


图片文件容量
单张图片小于 10 MB。
使用 base64 编码，请求体不可超过 64 MB。
使用文件路径上传方式，图片不能超过 512 MB。

token 用量说明
token 用量，根据图片宽高像素计算可得。图片转化 token 的公式为：

min(image_width * image_hight ÷ 784, max_image_tokens)
detail:high模式下，单图 token 限制(max_image_tokens)为 5120 token。
detail:low模式下，单图 token 限制(max_image_tokens)为 1312 token。
图片尺寸为 1280 px × 720 px，即宽为 1280 px，高为 720 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为1280×720÷784=1176，因为小于 1312，消耗 token 数为 1176 。
图片尺寸为 1920 px × 1080 px，即宽为 1920 px，高为 1080 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为1920×1080÷784=2645，因为大于 1312，消耗 token 数为 1312 。这时会压缩 token，即图片的细节会丢失部分，譬如字体很小的图片，模型可能就无法准确识别文字内容。

图片格式说明
支持的图片格式如下表，注意文件后缀匹配图片格式，即图片文件扩展名（URL传入时）、图片格式声明（Base64 编码传入时）需与图片实际信息一致。

图片格式

文件扩展名

内容格式 Content Type

上传文件至对象存储时设置，详情请参见文档。
Base64 编码输入
图片格式指定需使用小写
JPEG

.jpg, .jpeg

image/jpeg

PNG

.png

image/png

GIF

.gif

image/gif

WEBP

.webp

image/webp

BMP

.bmp

image/bmp

TIFF

.tiff, .tif

image/tiff

ICO

.ico

image/ico

DIB

.dib

image/bmp

ICNS

.icns

image/icns

SGI

.sgi

image/sgi

JPEG2000

.j2c, .j2k, .jp2, .jpc, .jpf, .jpx

image/jp2

HEIC

.heic

image/heic

doubao-1.5-vision-pro及以后模型支持

HEIF

.heif

image/heif

doubao-1.5-vision-pro及以后模型支持

说明

TIFF、 SGI、ICNS、JPEG2000 几种格式图片，需保证和元数据对齐，如在对象存储中正确设置文件元数据，否则会解析失败，详细请参见 使用视觉理解模型时，报错InvalidParameter？


API 参数字段说明
以下字段视觉理解暂不支持。

不支持设置频率惩罚系数，无 frequency_penalty 字段。
不支持设置存在惩罚系数，presence_penalty 字段。
不支持为单个请求生成多个返回，无 n 字段。

常见问题

文本生成
最近更新时间：2025.12.04 15:45:07
首次发布时间：2025.12.04 15:45:07
复制全文
我的收藏
有用
无用
文本生成模型能够基于输入的提示词生成连贯且有意义的文本内容。
Responses API 支持更简洁的输入输出格式，能够更加高效地进行上下文管理，推荐在项目中使用。

说明

首次使用方舟大模型服务，请通过快速入门，逐步完成首次调用。


支持模型
250615之后版本的大语言模型，如无特殊说明，默认支持 Responses API，方舟平台大语言模型列表，请参见：文本生成能力。

doubao-1-5-pro-32k-character-250715 模型不支持 Responses API。


快速开始
Curl
Python
Go
Java
OpenAI SDK
curl https://ark.cn-beijing.volces.com/api/v3/responses \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "model": "doubao-seed-1-6-251015",
      "input": "hello"
  }'

API文档
Responses API

上下文管理
上下文状态管理简单，默认情况下每个请求的输入和回复（不包括思维链内容） 都会持久化存储，后续请求只需传入 id 就可以引入对应请求的输入和回复，无需像 Chat API 每次请求，传入历史对话。详细信息，参见工作原理及使用说明。

多轮对话
在多轮调用模式下，系统能够自动管理上下文，持续追踪和记忆之前的对话内容，使对话更加连贯自然，提升智能交互体验。

Curl
Python
Go
Java
OpenAI SDK
curl https://ark.cn-beijing.volces.com/api/v3/responses \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "model": "doubao-seed-1-6-251015",
      "input": "Hi，讲个笑话。"
  }'
curl https://ark.cn-beijing.volces.com/api/v3/responses \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "model": "doubao-seed-1-6-251015",
      "previous_response_id":"<id>",
      "input": "这个笑话的笑点在哪？"
  }'
第二次请求需将 curl 命令中的 <id> 替换为上一次请求返回的 Response id。


重新生成对话
这段代码展示了 Responses API 中通过灵活调用 previous_response_id 重新生成对话的树状分叉结构，并展示了如何在不同的分支中进行不同的操作。在重新生成对话的场景中，系统能够根据不同的分支条件，灵活地执行多种的操作，从而实现更复杂的对话逻辑。

Python
Go
Java
OpenAI SDK
import os
from volcenginesdkarkruntime import Ark

# Get API Key：https://console.volcengine.com/ark/region:ark+cn-beijing/apikey
api_key = os.getenv('ARK_API_KEY')

client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

# Create the first-round conversation request
response = client.responses.create(
    model="doubao-seed-1-6-251015",
    input=[{"role": "user", "content": "你知道余弦相似度的原理吗？"}],
    store=True,  # store the conversation
)
print(response)

# Create the second-round conversation request
second_response = client.responses.create(
    model="doubao-seed-1-6-251015",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "我希望你可以用小学生都能听懂的方式来解释这个问题"}],
    store=True, 
)
print(second_response)

# Recreate the second-round conversation request
re_second_response = client.responses.create(
    model="doubao-seed-1-6-251015",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "我希望你可以用教授的思考逻辑来解释这个问题"}],
    store=True,  
)
print(re_second_response)

窗口截断
这段代码展示了如何利用 delete 接口实现 Responses API 的窗口截断的功能，使得程序可以在 response 粒度上管理历史记忆，便于后续进行更复杂的对话。

Python
Go
Java
OpenAI SDK
import os
from volcenginesdkarkruntime import Ark

# Get API Key：https://console.volcengine.com/ark/region:ark+cn-beijing/apikey
api_key = os.getenv('ARK_API_KEY')

client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-251015",
    input="讲个谐音梗笑话",
)
print(response)

second_response = client.responses.create(
    model="doubao-seed-1-6-251015",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "讲个有哲理的笑话"}],
)
print(second_response)

third_response = client.responses.create(
    model="doubao-seed-1-6-251015",
    previous_response_id=second_response.id,
    input=[{"role": "user", "content": "讲个冷笑话"}],
)
print(third_response)

deleting_response = client.responses.delete(second_response.id)
print(deleting_response)

fourth_response = client.responses.create(
    model="doubao-seed-1-6-251015",
    previous_response_id=third_response.id,
    input=[{"role": "user", "content": "你刚刚讲了几个笑话？都是关于什么主题的？"}],
)
print(fourth_response)

流式输出
流式输出支持内容动态实时呈现，既能够缓解用户等待焦虑，又可以规避复杂任务因长时间推理引发的客户端超时失败问题，保障请求流程顺畅。

Curl
Python
Go
Java
OpenAI SDK
curl https://ark.cn-beijing.volces.com/api/v3/responses \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "model": "doubao-seed-1-6-251015",
      "input": "常见的十字花科植物有哪些？",
      "thinking":{"type": "enabled"},
      "stream": true
  }'
输出示例：

event: response.created
data: {"type":"response.created","response":{"created_at":1764229579,"id":"resp_021764229578658fe9a0f6cb2cc6c828e7a59adbdb971872aee70","max_output_tokens":32768,"model":"doubao-seed-1-6-251015","object":"response","thinking":{"type":"enabled"},"service_tier":"default","caching":{"type":"disabled"},"store":true,"expire_at":1764488778},"sequence_number":0}

event: response.in_progress
data: {"type":"response.in_progress","response":{"created_at":1764229579,"id":"resp_021764229578658fe9a0f6cb2cc6c828e7a59adbdb971872aee70","max_output_tokens":32768,"model":"doubao-seed-1-6-251015","object":"response","thinking":{"type":"enabled"},"service_tier":"default","caching":{"type":"disabled"},"store":true,"expire_at":1764488778},"sequence_number":1}

event: response.output_item.added
data: {"type":"response.output_item.added","output_index":0,"item":{"id":"rs_02176422957963700000000000000000000ffffac15dd335c9c43","type":"reasoning","status":"in_progress"},"sequence_number":2}

event: response.reasoning_summary_part.added
data: {"type":"response.reasoning_summary_part.added","item_id":"rs_02176422957963700000000000000000000ffffac15dd335c9c43","output_index":0,"summary_index":0,"part":{"type":"summary_text"},"sequence_number":3}

event: response.reasoning_summary_text.delta
data: {"type":"response.reasoning_summary_text.delta","summary_index":0,"delta":"
","item_id":"rs_02176422957963700000000000000000000ffffac15dd335c9c43","output_index":0,"sequence_number":4}

event: response.reasoning_summary_text.delta
data: {"type":"response.reasoning_summary_text.delta","summary_index":0,"delta":"用户","item_id":"rs_02176422957963700000000000000000000ffffac15dd335c9c43","output_index":0,"sequence_number":5}

event: response.reasoning_summary_text.delta
data: {"type":"response.reasoning_summary_text.delta","summary_index":0,"delta":"问","item_id":"rs_02176422957963700000000000000000000ffffac15dd335c9c43","output_index":0,"sequence_number":6}
...





补充系统提示词
在Response API中，instructions字段用于在特定轮次中补充系统提示词，其核心机制是在对话上下文头部新增一条系统提示信息，实现更灵活的输出。

配置 instructions 字段后无法写入缓存以及使用缓存，即无法配置 caching 字段为{"type"："enabled"}，同时无法命中缓存。

Python
Go
Java
OpenAI SDK
import os
from volcenginesdkarkruntime import Ark

# Get API Key：https://console.volcengine.com/ark/region:ark+cn-beijing/apikey
api_key = os.getenv('ARK_API_KEY')

client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=api_key,
)

response = client.responses.create(
    model="doubao-seed-1-6-251015",    
    input=[
        {
            "role": "system", 
            "content": "你是一位数学老师，能够讲清楚相应的数学问题。"
        },
    ]
)
print(response)

second_response = client.responses.create(
    model="doubao-seed-1-6-251015",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "请解释一下余弦相似度原理"}],
)
print(second_response)

third_response = client.responses.create(
    model="doubao-seed-1-6-251015",
    instructions="增加一个要求：我希望你可以用小学生能听懂的方式解释这个问题。",
    previous_response_id=response.id,
    input=[{"role": "user", "content": "请解释一下余弦相似度原理"}],
)
print(third_response)

工作原理及使用说明

上下文管理工作原理
上下文管理流程如下：


item：为任意角色的一条信息，包括系统信息、用户信息、模型信息、思维链信息、工具信息等。
response_id：代表本轮请求输入 item + 回答 item。
输入 item：previous_response_id 指代的 item + 本轮新输入item。通过链表的形式串联之前轮次的对话，形成新的输入。

使用说明
默认开启存储功能，支持通过设置"store": true 启用 / "store": false 关闭。

存储条件：本次请求回复完毕且成功（返回 status 字段为completed），或者回复触发了长度限制导致截断（status 字段为 incomplete）都会将本轮记录存储。当思维链内容触发了长度限制导致截断，在查询模型响应时返回 output 为空。
输入限制：最多支持 1000 个 item（任意角色的一条信息为 1 个 item，如一问一答为2个item）。达到此限制，无法继续对话，可通过删除模型请求接口(https://www.volcengine.com/docs/82379/1584286) 手动清理记录。
存储时长：默认存储 3 天，可通过 expire_at 字段自定义设置，最长支持 7 天。
存储内容：存储 input 和 output 字段的信息，不存储思维链内容。
其他说明：store 功能当前不收取费用；数据会采用加密方式，确保信息安全和隐私合规。

QPS 限流
Responses API QPS 限流如下。如果需要提升限流值，请提交工单。

接口名称

账号维度的 QPS 限流

创建模型响应

无

查询模型响应

20

列出输入项

20

删除模型响应

20